{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char rnn for code prediction in Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sample import SampleClass\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_class = SampleClass(\"weights.01-0.88.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded up some weights we can generate code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next line we'll generate the 3 most probable line endings using beam search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parser = argparse.ArgumentParser() \n",
      "parser = argparse.ArgumentParser(args) \n",
      "parser = argparse.ArgumentParser(args=['--parameter']) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sample_class.sample(num_chars=60, seed=\"parser = argp\", greedy=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the first prediction is correct! :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to complete a comonly used line using greedy character selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i in self.set_status_status_status_status_code(self.context)): \n",
      "            return self.context.get('c\n"
     ]
    }
   ],
   "source": [
    "print(sample_class.sample(seed='for i in ', num_chars=100, greedy=True, random=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print out the probabilities of the next chars we can see that the network wasn't sure what goes after \"for i in\" so it chose the most probable char \"s\" and then continued in that direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -,   -,   -,   -,   -,   -,   -,   -,   -, 0.1, 0.8, 0.9, 0.9, 0.9, 0.1, 0.2, 0.2, 0.4, 0.1, 0.3, 0.7, 0.7, 0.6\n",
      "  f,   o,   r,    ,   i,    ,   i,   n,    ,   s,   e,   l,   f,   .,   s,   e,   t,   _,   s,   t,   a,   t,   u\n",
      "for i in self.set_statu\n"
     ]
    }
   ],
   "source": [
    "print(sample_class.sample(seed='for i in ', num_chars=14, greedy=True, random=False, probs=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with greedy char selection is that it will always choose the next most probable char, not taking into account the most probable line. If we use beam search then the results are much more relevant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i in range(10): \n",
      "for i in range(1000): \n",
      "for i in range(len(self.seq)): \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sample_class.sample(seed='for i in ', num_chars=100, greedy=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can generate completely random code, each run will give us a new result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dder=False, resource_id='/', status=403) \n",
      "      write_state(stream) \n",
      "      return ('commands' if ret, reset)\n",
      "\n",
      "\n",
      "MAILW_errorHash.return_value.values.insertifier(url, lnt_error)\n",
      "\n",
      "\n",
      "hore.create(self.client.password, service=context, mock_security_group_error_type='read_requires_host_manager', unicode_flags=environer, algorithm='test_nemone') \n",
      "      self.ts.remove_workers(msg)\n",
      "\n",
      "\n",
      ":/      ()'\n",
      "\n",
      "\n",
      "spolly-unsection_approvals' % (eval_mids, self.engine))\n",
      "\n",
      "\n",
      " \n",
      "      else: \n",
      "            line = ((('text' + r\n",
      "-------------------------------------------------\n",
      "USET)' \n",
      "      self.assertEqual(result, 59)\n",
      "\n",
      "\n",
      "-NEW_IDINProtocols,      e:      ignore      description      last      !(a = mp((n * 3))) \n",
      "      Equal(WinitImport('A', FEAME), 'This      is      be      local', 'Back') \n",
      "      m.add_match('alnomestage_') \n",
      "      assert (len(reducer.links) == 0.3) \n",
      "      assert_(a[0] = params \n",
      "      self.keys[1] = n\n",
      "\n",
      "\n",
      "end_toartilation()\n",
      "\n",
      "\n",
      "app.extending_email[0] \n",
      "      return self.fail(self.extract_browser)\n",
      "\n",
      "\n",
      "rmulin, asl1, bOk)\n",
      "\n",
      "\n",
      " \n",
      "      else: \n",
      "      \n",
      "-------------------------------------------------\n",
      "9bG!'})\n",
      "\n",
      "\n",
      "_stackAssertEqual(SCRYPT_NAME, ssl_error_dir_status, 'ORITIFIER')\n",
      "\n",
      "\n",
      "[u'HTTP_OVER_FAKE'] = ActionDomainSubprocessingObjectSibling(id=objects.Options.OutputFieldSubnetType) \n",
      "      extra_id = getattr(self.ctx, 'mode') \n",
      "      if isinstance(item, list): \n",
      "            item_mode_dict.clear() \n",
      "            id_id = uuid.uuid4().hex\n",
      "\n",
      "\n",
      " \n",
      "            return instance.pig_content_id.id \n",
      "      else: \n",
      "            if (viult is None): \n",
      "                  if info[item]: \n",
      "             DC\n",
      "-------------------------------------------------\n",
      "\\\\.('      \\\\,):\\n            {'translate': data}) \n",
      "      return iter(self._obj)\n",
      "\n",
      "\n",
      "dkeyme \n",
      "      return self._test_search_member_for_multiple(context, instance, key}\n",
      "\n",
      "\n",
      "ndex.m)\n",
      "\n",
      "\n",
      "_to_adds)\n",
      "\n",
      "\n",
      " else self.max_func1_db_system)\n",
      "\n",
      "\n",
      "', 'rating-jdMsg')\n",
      "\n",
      "\n",
      " \n",
      "      (recvion, dup) = rem_idnow(ofproto.OFPET_EXPERIMENTER_SHACH, get_char_width, **kwds) \n",
      "      parsed_icon = self.sample_decoder.complex() \n",
      "      if isinstance(point) in pads_process_shapes: \n",
      "            pretty_cookies = ([pos].replace('.', '')\n",
      "-------------------------------------------------\n",
      "AXE') \n",
      "      self._assert_service_io(response, 'DELETING')\n",
      "\n",
      "\n",
      "uild(self.request.manage.provider)\n",
      "\n",
      "\n",
      " \n",
      "      self.conn.connection_name = new_network\n",
      "\n",
      "\n",
      "gent \n",
      "      self.io_url = id \n",
      "      self.fileName = filename, file) \n",
      "      self.refryses = JRIARES.getCommit()\n",
      "\n",
      "\n",
      "r['_arrayhed'] \n",
      "      self.value = rep\n",
      "\n",
      "\n",
      " \n",
      "      quint_attrs = u'Avgs:{}      cobsiblings      isInstallect' \n",
      "      identities = (1.0) \n",
      "      position = cild.items().astype(current_key, node.total_actions[0]) \n",
      "      def\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(sample_class.sample(seed='', num_chars=500, greedy=True, random=True))\n",
    "    print('-------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use beam search for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ") \n",
      "      self.assertEqual(s) \n",
      "      self.assertEqual(l) \n",
      "      self.assertEqual(r\n",
      "---------------------\n",
      "self.assertRaises(ValueError, self.assertEqual(len(self.contself.assertEqual(len(self.conn\n",
      "---------------------\n",
      "      self.assertEqual(len(sel      self.assertEqual(self.co      self.assertEqual(self.se\n",
      "---------------------\n",
      "                                    self.assertEqual(len(sel      self.assertEqual(self.co\n",
      "---------------------\n",
      "name) \n",
      "      self.assertEquname) \n",
      "      self.assertTruname) \n",
      "      return self.__\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(sample_class.sample(seed='', num_chars=30, greedy=False, random=True, eos=\"nema\"))\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the results aren't that interesting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
